#!/usr/bin/env python3
"""
DDInter2 Ultimate Scraper v10 - API Edition
============================================
Ø³ÙƒØ±Ø§Ø¨Ø± Ù†Ù‡Ø§Ø¦ÙŠ ÙŠØ³ØªØ®Ø¯Ù… API endpoints Ø§Ù„Ù…ÙƒØªØ´ÙØ©
- Ø³Ø±Ø¹Ø© ÙØ§Ø¦Ù‚Ø© (100x Ø£Ø³Ø±Ø¹ Ù…Ù† Selenium)
- Ø¯Ø¹Ù… Resume/Ø§Ø³ØªÙƒÙ…Ø§Ù„ ÙƒØ§Ù…Ù„
- ÙŠØ¹Ù…Ù„ Ø¹Ù„Ù‰ GitHub Actions
- Ø¬Ù…Ø¹ Ø´Ø§Ù…Ù„ Ù„Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª

API Endpoints Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…Ø©:
- /server/interact-with/{drug_id}/       â†’ Drug-Drug interactions
- /server/interact-with-food/{drug_id}/  â†’ Drug-Food interactions  
- /server/interact-with-multi/{drug_id}/ â†’ Compound preparations
"""

import requests
import sqlite3
import json
import os
import time
import urllib3
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime
from bs4 import BeautifulSoup
import threading

urllib3.disable_warnings(urllib3.exceptions.InsecureRequestWarning)

# ============================================
# Configuration
# ============================================
DB_PATH = 'ddinter_complete.db'
SCHEMA_SQL = 'database_schema.sql'
DRUG_IDS_FILE = 'discovered_ids.json'
BASE_URL = 'https://ddinter2.scbdd.com'
MAX_WORKERS = 25
REQUEST_TIMEOUT = 15

HEADERS = {
    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
    'Accept': 'application/json, text/javascript, */*; q=0.01',
    'Accept-Language': 'en-US,en;q=0.9',
    'Content-Type': 'application/x-www-form-urlencoded; charset=UTF-8',
    'X-Requested-With': 'XMLHttpRequest',
    'Referer': 'https://ddinter2.scbdd.com/',
    'Connection': 'keep-alive'
}

# Thread-safe counters
class Counter:
    def __init__(self):
        self.value = 0
        self.lock = threading.Lock()
    def increment(self):
        with self.lock:
            self.value += 1
            return self.value
    def get(self):
        with self.lock:
            return self.value

stats = {
    'drugs_processed': Counter(),
    'ddi_fetched': Counter(),
    'dfi_fetched': Counter(),
    'multi_fetched': Counter(),
    'errors': Counter()
}

# ============================================
# Database Functions
# ============================================
def init_database():
    """Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    print("ğŸ“¦ Initializing database...")
    
    if not os.path.exists(SCHEMA_SQL):
        print(f"âŒ Schema file not found: {SCHEMA_SQL}")
        return False
    
    conn = sqlite3.connect(DB_PATH)
    with open(SCHEMA_SQL, 'r', encoding='utf-8') as f:
        conn.executescript(f.read())
    conn.commit()
    conn.close()
    
    print(f"âœ… Database initialized: {DB_PATH}")
    return True

def load_drug_ids():
    """ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ù…Ø¹Ø±ÙØ§Øª Ø§Ù„Ø£Ø¯ÙˆÙŠØ©"""
    if not os.path.exists(DRUG_IDS_FILE):
        print(f"âŒ Drug IDs file not found: {DRUG_IDS_FILE}")
        return []
    
    with open(DRUG_IDS_FILE, 'r') as f:
        data = json.load(f)
        drug_ids = data.get('unique_drugs', [])
        print(f"ğŸ“‹ Loaded {len(drug_ids)} drug IDs")
        return drug_ids

def mark_drug_processed(drug_id, status='completed', error_msg=None):
    """ØªØ³Ø¬ÙŠÙ„ Ø­Ø§Ù„Ø© Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ø¯ÙˆØ§Ø¡"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    try:
        c.execute('''
            INSERT OR REPLACE INTO scraping_progress (entity_type, entity_id, status, error_message)
            VALUES ('drug', ?, ?, ?)
        ''', (drug_id, status, error_msg))
        conn.commit()
    finally:
        conn.close()

def get_pending_drugs(all_drug_ids):
    """Ø§Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„ØªÙŠ Ù„Ù… ØªØªÙ… Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT entity_id FROM scraping_progress WHERE entity_type='drug' AND status='completed'")
    processed = set(row[0] for row in c.fetchall())
    conn.close()
    
    pending = [drug_id for drug_id in all_drug_ids if drug_id not in processed]
    print(f"ğŸ“Š Status: {len(processed)} completed, {len(pending)} pending")
    return pending

# ============================================
# HTML Scraping (Basic Info)
# ============================================
def extract_table_value(soup, key_text):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ù‚ÙŠÙ…Ø© Ù…Ù† Ø¬Ø¯ÙˆÙ„ HTML"""
    try:
        import re
        key_td = soup.find('td', class_='key', string=re.compile(key_text, re.I))
        if key_td:
            value_td = key_td.find_next_sibling('td', class_='value')
            if value_td:
                return value_td.get_text(strip=True)
    except:
        pass
    return None

def extract_drug_basic_info(drug_id):
    """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© Ù„Ù„Ø¯ÙˆØ§Ø¡ Ù…Ù† ØµÙØ­Ø© drug-detail"""
    url = f"{BASE_URL}/server/drug-detail/{drug_id}/"
    
    try:
        response = requests.get(url, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
        if response.status_code != 200:
            return None
        
        soup = BeautifulSoup(response.text, 'html.parser')
        
        # Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ø³Ù… Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù…Ù† Ø§Ù„Ø¹Ù†ÙˆØ§Ù†
        drug_name = None
        title_elem = soup.find('strong', string='Drugs Information:')
        if title_elem and title_elem.next_sibling:
            drug_name = title_elem.next_sibling.strip()
        
        drug_data = {
            'ddinter_id': drug_id,
            'drug_name': drug_name,
            'drug_type': extract_table_value(soup, 'Drug Type'),
            'molecular_formula': extract_table_value(soup, 'Molecular Formula'),
            'molecular_weight': extract_table_value(soup, 'Molecular Weight'),
            'cas_number': extract_table_value(soup, 'CAS Number'),
            'description': extract_table_value(soup, 'Description'),
            'iupac_name': extract_table_value(soup, 'IUPAC Name'),
            'inchi': extract_table_value(soup, 'InChI'),
            'smiles': extract_table_value(soup, 'Canonical SMILES')
        }
        
        return drug_data
        
    except Exception as e:
        print(f"âš ï¸ Error fetching basic info for {drug_id}: {e}")
        return None

# ============================================
# API Calls (Interactions)
# ============================================
def fetch_drug_drug_interactions(drug_id):
    """Ø¬Ù„Ø¨ ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-Ø¯ÙˆØ§Ø¡ Ø¹Ø¨Ø± API"""
    url = f"{BASE_URL}/server/interact-with/{drug_id}/"
    interactions = []
    
    try:
        # Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø© Ø§Ù„Ø£ÙˆÙ„Ù‰ Ù„Ù…Ø¹Ø±ÙØ© Ø§Ù„Ø¹Ø¯Ø¯ Ø§Ù„ÙƒÙ„ÙŠ
        data = {
            'draw': 1,
            'start': 0,
            'length': 100,  # Ø¬Ù„Ø¨ 100 ÙÙŠ ÙƒÙ„ Ù…Ø±Ø©
            'severity': '',
            'mechanism': ''
        }
        
        response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
        if response.status_code != 200:
            return []
        
        json_response = response.json()
        total_records = json_response.get('recordsTotal', 0)
        interactions.extend(json_response.get('data', []))
        
        # Ø¬Ù„Ø¨ Ø§Ù„ØµÙØ­Ø§Øª Ø§Ù„Ù…ØªØ¨Ù‚ÙŠØ©
        for offset in range(100, total_records, 100):
            data['start'] = offset
            data['draw'] += 1
            
            response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
            if response.status_code == 200:
                json_response = response.json()
                interactions.extend(json_response.get('data', []))
                
        stats['ddi_fetched'].increment()
        return interactions
        
    except Exception as e:
        print(f"âš ï¸ Error fetching DDI for {drug_id}: {e}")
        return []

def fetch_drug_food_interactions(drug_id):
    """Ø¬Ù„Ø¨ ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-ØºØ°Ø§Ø¡ Ø¹Ø¨Ø± API"""
    url = f"{BASE_URL}/server/interact-with-food/{drug_id}/"
    interactions = []
    
    try:
        data = {
            'draw': 1,
            'start': 0,
            'length': 100,
            'severity': '',
            'mechanism': ''
        }
        
        response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
        if response.status_code != 200:
            return []
        
        json_response = response.json()
        total_records = json_response.get('recordsTotal', 0)
        interactions.extend(json_response.get('data', []))
        
        for offset in range(100, total_records, 100):
            data['start'] = offset
            data['draw'] += 1
            
            response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
            if response.status_code == 200:
                json_response = response.json()
                interactions.extend(json_response.get('data', []))
        
        stats['dfi_fetched'].increment()
        return interactions
        
    except Exception as e:
        print(f"âš ï¸ Error fetching DFI for {drug_id}: {e}")
        return []

def fetch_compound_preparations(drug_id):
    """Ø¬Ù„Ø¨ Ø§Ù„Ù…Ø³ØªØ­Ø¶Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø© Ø¹Ø¨Ø± API"""
    url = f"{BASE_URL}/server/interact-with-multi/{drug_id}/"
    preparations = []
    
    try:
        data = {
            'draw': 1,
            'start': 0,
            'length': 100
        }
        
        response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
        if response.status_code != 200:
            return []
        
        json_response = response.json()
        total_records = json_response.get('recordsTotal', 0)
        preparations.extend(json_response.get('data', []))
        
        for offset in range(100, total_records, 100):
            data['start'] = offset
            data['draw'] += 1
            
            response = requests.post(url, data=data, headers=HEADERS, timeout=REQUEST_TIMEOUT, verify=False)
            if response.status_code == 200:
                json_response = response.json()
                preparations.extend(json_response.get('data', []))
        
        stats['multi_fetched'].increment()
        return preparations
        
    except Exception as e:
        print(f"âš ï¸ Error fetching preparations for {drug_id}: {e}")
        return []

# ============================================
# Database Saving
# ============================================
def save_drug_data(drug_data, ddi_list, dfi_list, prep_list):
    """Ø­ÙØ¸ Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¡ ÙÙŠ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª"""
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    
    try:
        # 1. Ø­ÙØ¸ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        c.execute('''
            INSERT OR REPLACE INTO drugs 
            (ddinter_id, drug_name, drug_type, molecular_formula, molecular_weight, 
             cas_number, description, iupac_name, inchi, smiles)
            VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
        ''', (
            drug_data['ddinter_id'], drug_data['drug_name'], drug_data['drug_type'],
            drug_data['molecular_formula'], drug_data['molecular_weight'],
            drug_data['cas_number'], drug_data['description'], drug_data['iupac_name'],
            drug_data['inchi'], drug_data['smiles']
        ))
        
        # 2. Ø­ÙØ¸ ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-Ø¯ÙˆØ§Ø¡ (Ù„ÙƒÙ† ÙÙ‚Ø· Ø¥Ø°Ø§ ÙƒØ§Ù† Ù‡Ø°Ø§ Ø§Ù„Ø¯ÙˆØ§Ø¡ Ù‡Ùˆ drug_a)
        # Ù„ØªØ¬Ù†Ø¨ Ø§Ù„ØªÙƒØ±Ø§Ø±ØŒ Ù†Ø­ÙØ¸ ÙÙ‚Ø· Ø¹Ù†Ø¯Ù…Ø§ ÙŠÙƒÙˆÙ† Ø§Ù„Ø¯ÙˆØ§Ø¡ Ø§Ù„Ø­Ø§Ù„ÙŠ Ù‡Ùˆ Ø§Ù„Ø£ÙˆÙ„ alphabetically
        for interaction in ddi_list:
            # Ù†Ø­ÙØ¸ interaction_id ÙÙ‚Ø· Ù…Ø±Ø© ÙˆØ§Ø­Ø¯Ø©
            c.execute('''
                INSERT OR IGNORE INTO drug_drug_interactions 
                (interaction_id, drug_a_id, drug_b_id, severity, source_url)
                VALUES (?, ?, ?, ?, ?)
            ''', (
                interaction.get('interaction_id'),
                drug_data['ddinter_id'],
                interaction.get('drug_id'),
                {1: 'Minor', 2: 'Moderate', 3: 'Major'}.get(interaction.get('level'), 'Unknown'),
                f"{BASE_URL}/server/interact/{interaction.get('interaction_id')}/"
            ))
        
        # 3. Ø­ÙØ¸ ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-ØºØ°Ø§Ø¡
        for interaction in dfi_list:
            c.execute('''
                INSERT OR IGNORE INTO drug_food_interactions 
                (drug_id, food_name, severity, description, management, mechanism_flags)
                VALUES (?, ?, ?, ?, ?, ?)
            ''', (
                drug_data['ddinter_id'],
                interaction.get('foodName'),
                {1: 'Minor', 2: 'Moderate', 3: 'Major'}.get(int(interaction.get('level', 0)), 'Unknown'),
                interaction.get('newInteraction'),
                interaction.get('newManagement'),
                interaction.get('magnesium')
            ))
        
        # 4. Ø­ÙØ¸ Ø§Ù„Ù…Ø³ØªØ­Ø¶Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
        for prep in prep_list:
            c.execute('''
                INSERT OR IGNORE INTO compound_preparations 
                (drug_id, preparation_name, components, interaction_info)
                VALUES (?, ?, ?, ?)
            ''', (
                drug_data['ddinter_id'],
                prep.get('trade_name'),
                json.dumps(prep.get('multi_drug', [])),
                prep.get('warning')
            ))
        
        conn.commit()
        return True
        
    except Exception as e:
        conn.rollback()
        print(f"âŒ Error saving {drug_data['ddinter_id']}: {e}")
        return False
    finally:
        conn.close()

# ============================================
# Main Processing
# ============================================
def process_single_drug(drug_id):
    """Ù…Ø¹Ø§Ù„Ø¬Ø© Ø¯ÙˆØ§Ø¡ ÙˆØ§Ø­Ø¯ - Ø¬Ù„Ø¨ Ø¬Ù…ÙŠØ¹ Ø¨ÙŠØ§Ù†Ø§ØªÙ‡"""
    try:
        # 1. Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ©
        drug_data = extract_drug_basic_info(drug_id)
        if not drug_data:
            mark_drug_processed(drug_id, 'failed', 'Failed to fetch basic info')
            stats['errors'].increment()
            return False
        
        # 2. ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-Ø¯ÙˆØ§Ø¡
        ddi_list = fetch_drug_drug_interactions(drug_id)
        
        # 3. ØªÙØ§Ø¹Ù„Ø§Øª Ø¯ÙˆØ§Ø¡-ØºØ°Ø§Ø¡
        dfi_list = fetch_drug_food_interactions(drug_id)
        
        # 4. Ø§Ù„Ù…Ø³ØªØ­Ø¶Ø±Ø§Øª Ø§Ù„Ù…Ø±ÙƒØ¨Ø©
        prep_list = fetch_compound_preparations(drug_id)
        
        # 5. Ø­ÙØ¸ ÙƒÙ„ Ø´ÙŠØ¡
        if save_drug_data(drug_data, ddi_list, dfi_list, prep_list):
            mark_drug_processed(drug_id, 'completed')
            
            count = stats['drugs_processed'].increment()
            if count % 10 == 0:
                print(f"âœ… Progress: {count} drugs | DDI: {stats['ddi_fetched'].get()} | DFI: {stats['dfi_fetched'].get()} | Multi: {stats['multi_fetched'].get()} | Errors: {stats['errors'].get()}")
            
            return True
        else:
            mark_drug_processed(drug_id, 'failed', 'Database save failed')
            stats['errors'].increment()
            return False
            
    except Exception as e:
        mark_drug_processed(drug_id, 'failed', str(e))
        stats['errors'].increment()
        print(f"âŒ Error processing {drug_id}: {e}")
        return False

# ============================================
# Main Execution
# ============================================
def main():
    print("="*70)
    print("ğŸš€ DDInter2 Ultimate Scraper v10 - API Edition")
    print("="*70)
    print(f"â° Start time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    
    # 1. Ø¥Ù†Ø´Ø§Ø¡/ÙØªØ­ Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    if not os.path.exists(DB_PATH):
        if not init_database():
            return
    else:
        print(f"ğŸ“¦ Using existing database: {DB_PATH}")
    
    # 2. ØªØ­Ù…ÙŠÙ„ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø£Ø¯ÙˆÙŠØ©
    all_drug_ids = load_drug_ids()
    if not all_drug_ids:
        print("âŒ No drug IDs to process")
        return
    
    # 3. ÙÙ„ØªØ±Ø© Ø§Ù„Ø£Ø¯ÙˆÙŠØ© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© (Resume Support)
    pending_drugs = get_pending_drugs(all_drug_ids)
    
    if not pending_drugs:
        print("âœ… All drugs already processed!")
        return
    
    print(f"\nğŸ”„ Processing {len(pending_drugs)} drugs with {MAX_WORKERS} workers...\n")
    
    # 4. Ù…Ø¹Ø§Ù„Ø¬Ø© Ù…ØªÙˆØ§Ø²ÙŠØ©
    start_time = time.time()
    
    with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
        futures = {executor.submit(process_single_drug, drug_id): drug_id for drug_id in pending_drugs}
        
        for future in as_completed(futures):
            drug_id = futures[future]
            try:
                future.result()
            except Exception as e:
                print(f"âŒ Unexpected error for {drug_id}: {e}")
    
    elapsed = time.time() - start_time
    
    # 5. Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù†Ù‡Ø§Ø¦ÙŠØ©
    print("\n" + "="*70)
    print("ğŸ‰ Scraping Complete!")
    print("="*70)
    print(f"â±ï¸  Total time: {elapsed/60:.2f} minutes")
    print(f"âœ… Drugs processed: {stats['drugs_processed'].get()}")
    print(f"ğŸ“Š Drug-Drug interactions: {stats['ddi_fetched'].get()} drugs")
    print(f"ğŸ” Drug-Food interactions: {stats['dfi_fetched'].get()} drugs")
    print(f"ğŸ’Š Compound preparations: {stats['multi_fetched'].get()} drugs")
    print(f"âŒ Errors: {stats['errors'].get()}")
    print("="*70)
    
    # Ø¹Ø±Ø¶ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ù‚Ø§Ø¹Ø¯Ø© Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª
    conn = sqlite3.connect(DB_PATH)
    c = conn.cursor()
    c.execute("SELECT COUNT(*) FROM drugs")
    total_drugs = c.fetchone()[0]
    c.execute("SELECT COUNT(*) FROM drug_drug_interactions")
    total_ddi = c.fetchone()[0]
    c.execute("SELECT COUNT(*) FROM drug_food_interactions")
    total_dfi = c.fetchone()[0]
    c.execute("SELECT COUNT(*) FROM compound_preparations")
    total_prep = c.fetchone()[0]
    conn.close()
    
    print(f"\nğŸ“Š Database Statistics:")
    print(f"   Drugs: {total_drugs}")
    print(f"   Drug-Drug Interactions: {total_ddi}")
    print(f"   Drug-Food Interactions: {total_dfi}")
    print(f"   Compound Preparations: {total_prep}")
    print("="*70)

if __name__ == "__main__":
    main()
