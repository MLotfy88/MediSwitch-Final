#!/usr/bin/env python3
"""
Update Meds CSV from Scraped Details (Strict Overwrite Mode)
Reads: assets/meds_scraped_new.jsonl
Writes: assets/meds.csv (Complete Overwrite)
Backups: assets/meds_backup.csv, backups/meds_backup_DATE.csv
"""

import pandas as pd
import json
import os
import shutil
import sys
import datetime

# --- Path Configuration ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
SCRAPED_DB = os.path.join(BASE_DIR, 'assets', 'meds_scraped_new.jsonl')
MEDS_CSV = os.path.join(BASE_DIR, 'assets', 'meds.csv')
MEDS_BACKUP_CSV = os.path.join(BASE_DIR, 'assets', 'meds_backup.csv')
BACKUP_DIR = os.path.join(BASE_DIR, 'backups')

# --- Translation Dictionaries ---
MAIN_CATEGORIES = {
    'oncology': 'ÿπŸÑÿßÿ¨ ÿßŸÑÿ£Ÿàÿ±ÿßŸÖ',
    'diabetes_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ŸÖÿ±ÿ∂Ÿâ ÿßŸÑÿ≥ŸÉÿ±Ÿä',
    'skin_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ®ÿ¥ÿ±ÿ©',
    'eye_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿπŸäŸàŸÜ',
    'ear_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ£ÿ∞ŸÜ',
    'pain_management': 'ŸÖÿ≥ŸÉŸÜÿßÿ™ ÿßŸÑÿ£ŸÑŸÖ',
    'anesthetics': 'ÿßŸÑÿ™ÿÆÿØŸäÿ±',
    'anti_inflammatory': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑÿßŸÑÿ™Ÿáÿßÿ®',
    'antihistamine': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑŸáŸäÿ≥ÿ™ÿßŸÖŸäŸÜ',
    'anti_infective': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑÿπÿØŸàŸâ',
    'vitamins': 'ÿßŸÑŸÅŸäÿ™ÿßŸÖŸäŸÜÿßÿ™',
    'supplements': 'ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ©',
    'probiotics': 'ÿßŸÑÿ®ÿ±Ÿàÿ®ŸäŸàÿ™ŸäŸÉ',
    'respiratory': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿ™ŸÜŸÅÿ≥Ÿä',
    'digestive': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑŸáÿ∂ŸÖŸä',
    'cardiovascular': 'ÿßŸÑŸÇŸÑÿ® ŸàÿßŸÑÿ£ŸàÿπŸäÿ© ÿßŸÑÿØŸÖŸàŸäÿ©',
    'neurological': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿπÿµÿ®Ÿä',
    'urology': 'ÿßŸÑŸÖÿ≥ÿßŸÑŸÉ ÿßŸÑÿ®ŸàŸÑŸäÿ©',
    'soothing': 'ŸÖŸáÿØÿ¶ÿßÿ™',
    'cosmetics': 'ŸÖÿ≥ÿ™ÿ≠ÿ∂ÿ±ÿßÿ™ ÿßŸÑÿ™ÿ¨ŸÖŸäŸÑ',
    'personal_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿßŸÑÿ¥ÿÆÿµŸäÿ©',
    'medical_supplies': 'ŸÖÿ≥ÿ™ŸÑÿ≤ŸÖÿßÿ™ ÿ∑ÿ®Ÿäÿ©',
    'hormonal': 'ÿßŸÑŸáÿ±ŸÖŸàŸÜÿßÿ™',
    'hematology': 'ÿ£ŸÖÿ±ÿßÿ∂ ÿßŸÑÿØŸÖ',
    'musculoskeletal': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿπÿ∂ŸÑŸä ÿßŸÑŸáŸäŸÉŸÑŸä',
    'immunology': 'ÿßŸÑŸÖŸÜÿßÿπÿ©',
    'reproductive_health': 'ÿßŸÑÿµÿ≠ÿ© ÿßŸÑÿ•ŸÜÿ¨ÿßÿ®Ÿäÿ©',
    'herbal_natural': 'ÿ£ÿπÿ¥ÿßÿ® ŸàŸÖŸàÿßÿØ ÿ∑ÿ®ŸäÿπŸäÿ©',
    'baby_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ∑ŸÅŸÑ',
    'medical_devices': 'ÿ£ÿ¨Ÿáÿ≤ÿ© ÿ∑ÿ®Ÿäÿ©',
    'diagnostics': 'ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ',
    'other': 'ÿ£ÿÆÿ±Ÿâ'
}

DOSAGE_FORM_TRANSLATIONS = {
    'tablet': 'ÿ£ŸÇÿ±ÿßÿµ', 'tablets': 'ÿ£ŸÇÿ±ÿßÿµ', 'tab': 'ÿ£ŸÇÿ±ÿßÿµ', 'tabs': 'ÿ£ŸÇÿ±ÿßÿµ', 'tabs.': 'ÿ£ŸÇÿ±ÿßÿµ',
    'capsule': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™', 'capsules': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™', 'cap': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™', 'caps': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™',
    'syrup': 'ÿ¥ÿ±ÿßÿ®', 'suspension': 'ŸÖÿπŸÑŸÇ', 'susp': 'ŸÖÿπŸÑŸÇ',
    'injection': 'ÿ≠ŸÇŸÜ', 'inj': 'ÿ≠ŸÇŸÜ', 'ampoule': 'ÿ£ŸÖÿ®ŸàŸÑ', 'ampoules': 'ÿ£ŸÖÿ®ŸàŸÑÿßÿ™', 'amp': 'ÿ£ŸÖÿ®ŸàŸÑ',
    'vial': 'ŸÅŸäÿßŸÑ', 'syringe': 'ÿ≠ŸÇŸÜÿ©', 'pen': 'ŸÇŸÑŸÖ',
    'cream': 'ŸÉÿ±ŸäŸÖ', 'ointment': 'ŸÖÿ±ŸáŸÖ', 'oint': 'ŸÖÿ±ŸáŸÖ', 'gel': 'ÿ¨ŸÑ',
    'lotion': 'ŸÑŸàÿ¥ŸÜ', 'solution': 'ŸÖÿ≠ŸÑŸàŸÑ', 'sol': 'ŸÖÿ≠ŸÑŸàŸÑ',
    'spray': 'ÿ®ÿÆÿßÿÆ', 'inhaler': 'ÿ¨Ÿáÿßÿ≤ ÿßÿ≥ÿ™ŸÜÿ¥ÿßŸÇ',
    'drops': 'ŸÜŸÇÿ∑', 'drop': 'ŸÜŸÇÿ∑', 'oral drops': 'ŸÜŸÇÿ∑ ŸÑŸÑŸÅŸÖ', 'ear drops': 'ŸÜŸÇÿ∑ ŸÑŸÑÿ£ÿ∞ŸÜ',
    'eye drops': 'ŸÜŸÇÿ∑ ŸÑŸÑÿπŸäŸÜ', 'nasal drops': 'ŸÜŸÇÿ∑ ŸÑŸÑÿ£ŸÜŸÅ', 'mouth drops': 'ŸÜŸÇÿ∑ ŸÑŸÑŸÅŸÖ',
    'eye ointment': 'ŸÖÿ±ŸáŸÖ ŸÑŸÑÿπŸäŸÜ',
    'suppository': 'ŸÑÿ®Ÿàÿ≥', 'suppositories': 'ŸÑÿ®Ÿàÿ≥', 'supp': 'ŸÑÿ®Ÿàÿ≥',
    'powder': 'ÿ®ŸàÿØÿ±ÿ©', 'sachet': 'ÿ£ŸÉŸäÿßÿ≥', 'sachets': 'ÿ£ŸÉŸäÿßÿ≥',
    'effervescent': 'ŸÅŸàÿßÿ±', 'eff': 'ŸÅŸàÿßÿ±',
    'lozenges': 'ÿßÿ≥ÿ™ÿ≠ŸÑÿßÿ®',
    'mouth wash': 'ÿ∫ÿ≥ŸàŸÑ ŸÑŸÑŸÅŸÖ', 'gargle': 'ÿ∫ÿ±ÿ∫ÿ±ÿ©', 'toothpaste': 'ŸÖÿπÿ¨ŸàŸÜ ÿ£ÿ≥ŸÜÿßŸÜ',
    'shampoo': 'ÿ¥ÿßŸÖÿ®Ÿà', 'conditioner': 'ÿ®ŸÑÿ≥ŸÖ', 'hair oil': 'ÿ≤Ÿäÿ™ ÿ¥ÿπÿ±',
    'soap': 'ÿµÿßÿ®ŸàŸÜ', 'facial wash': 'ÿ∫ÿ≥ŸàŸÑ ŸÑŸÑŸàÿ¨Ÿá', 'cleanser': 'ŸÖŸÜÿ∏ŸÅ',
    'patch': 'ŸÑÿµŸÇÿ©', 'film': 'ŸÅŸäŸÑŸÖ',
    'foam': 'ŸÅŸàŸÖ', 'paint': 'ŸÖÿ≥/ÿØŸáÿßŸÜ',
    'oil': 'ÿ≤Ÿäÿ™', 'serum': 'ÿ≥Ÿäÿ±ŸàŸÖ',
    'vaginal douche': 'ÿØÿ¥ ŸÖŸáÿ®ŸÑŸä', 'vaginal wash': 'ÿ∫ÿ≥ŸàŸÑ ŸÖŸáÿ®ŸÑŸä',
    'bottle': 'ÿ≤ÿ¨ÿßÿ¨ÿ©', 'piece': 'ŸÇÿ∑ÿπÿ©',
    'unknown': 'ÿ∫Ÿäÿ± ŸÖÿ≠ÿØÿØ'
}

def safe_str_lower(value):
    return str(value).lower() if value else ''

def main():
    print(f"üîÑ Updating meds.csv from {SCRAPED_DB}...")
    
    if not os.path.exists(SCRAPED_DB):
        print("‚ùå Scraped DB not found. Run scraper first.")
        sys.exit(1)
        
    # 1. Backup Existing CSVs (Safe Backup)
    if os.path.exists(MEDS_CSV):
        # Check if MEDS_CSV is valid/substantial before backing up
        # This prevents the scraper's "wipe" from destroying the backup source
        is_valid_csv = False
        try:
            if os.path.getsize(MEDS_CSV) > 100: # Arbitrary small threshold
                is_valid_csv = True
            else:
                # Double check line count
                with open(MEDS_CSV, 'r') as f:
                    if len(f.readlines()) > 5:
                         is_valid_csv = True
        except: pass

        if is_valid_csv:
            print("üíæ Creating Backups...")
            os.makedirs(BACKUP_DIR, exist_ok=True)
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # Backup 1: To backups/ folder with timestamp
            backup_path = os.path.join(BACKUP_DIR, f'meds_backup_{timestamp}.csv')
            shutil.copy(MEDS_CSV, backup_path)
            print(f"   -> {backup_path}")
            
            # Backup 2: To assets/meds_backup.csv (Overwrite previous backup)
            shutil.copy(MEDS_CSV, MEDS_BACKUP_CSV)
            print(f"   -> {MEDS_BACKUP_CSV}")
        else:
            print("‚ö†Ô∏è Skipping backup: meds.csv is too small/empty (preventing data loss).")

    # 2. Load Scraped Data
    scraped_map = {}
    print(f"üìÇ Loading scraped data...")
    with open(SCRAPED_DB, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    rec = json.loads(line)
                    mid = str(rec.get('id', ''))
                    if mid:
                        scraped_map[mid] = rec
                except json.JSONDecodeError as e:
                    print(f"‚ùå JSON Error in line: {e} | Content: {line[:50]}...")
                except Exception as e:
                    print(f"‚ùå Error parsing line: {e}")
    
    count = len(scraped_map)
    print(f"‚úÖ Loaded {count} scraped records.")
    
    if count == 0:
        print("‚ö†Ô∏è  Warning: Scraped data is empty! Aborting overwrite to prevent data loss.")
        sys.exit(1)

    # 3. Build New Records (Strict Overwrite)
    print("üî® Processing records (Wiping old data)...")
    records = []
    
    for mid, rec in scraped_map.items():
        # Handle date mapping robustly
        date_val = rec.get('last_update') or rec.get('last_price_update') or ''
        
        # Base Row
        row = {
            'id': mid,
            'trade_name': rec.get('trade_name', ''),
            'arabic_name': rec.get('arabic_name', ''),
            'price': rec.get('price', ''),
            'old_price': rec.get('old_price', ''),
            'active': rec.get('active', ''),
            'company': rec.get('company', ''),
            'category': rec.get('category', ''),
            'last_price_update': date_val,
            'visits': rec.get('visits', ''),
            'concentration': rec.get('concentration', ''),
            'pharmacology': rec.get('pharmacology', ''),
            'barcode': rec.get('barcode', ''),
            'unit': rec.get('units', ''),
            'dosage_form': rec.get('dosage_form', ''),
            'usage': rec.get('usage', ''),
        }
        
        # --- Translation & Enrichment ---
        
        # Dosage Form AR
        # 1. Try Scraper's translation first
        row['dosage_form_ar'] = rec.get('dosage_form_ar', '')
        
        # 2. If empty, try matching from map
        if not row['dosage_form_ar']:
            form_lower = safe_str_lower(row['dosage_form'])
            # Direct match
            row['dosage_form_ar'] = DOSAGE_FORM_TRANSLATIONS.get(form_lower, '')
            # Substring match fallback
            if not row['dosage_form_ar']:
                for key, val in DOSAGE_FORM_TRANSLATIONS.items():
                    if key in form_lower:
                        row['dosage_form_ar'] = val
                        break
        
        records.append(row)

    # 4. Create DataFrame & Save
    df = pd.DataFrame(records)
    
    # Define Column Order (Schema) - Removed usage_ar, category_ar, etc. per user request
    desired_columns = [
        'id', 'trade_name', 'arabic_name', 'price', 'old_price', 'active', 
        'company', 'dosage_form', 'dosage_form_ar', 
        'usage', 'category', 'concentration', 
        'pharmacology', 'barcode', 'unit', 'visits', 'last_price_update'
    ]
    
    # Ensure all columns exist
    for col in desired_columns:
        if col not in df.columns:
            df[col] = ''
            
    # Remove duplicates columns if any (by name)
    df = df.loc[:, ~df.columns.duplicated()]
    
    # Reorder and Select (Strict)
    df = df[desired_columns]
    
    # Save (Overwrite)
    df.to_csv(MEDS_CSV, index=False, encoding='utf-8-sig') # Use utf-8-sig for Excel compatibility
    print(f"‚úÖ SUCCESS: Wiped old data and wrote {len(df)} records to {MEDS_CSV}")

if __name__ == "__main__":
    main()
