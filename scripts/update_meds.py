#!/usr/bin/env python3
"""
Update Meds CSV from Scraped Details (Strict Overwrite Mode)
Reads: assets/meds_scraped_new.jsonl
Writes: assets/meds.csv (Complete Overwrite)
Backups: assets/meds_backup.csv, backups/meds_backup_DATE.csv
"""

import pandas as pd
import json
import os
import shutil
import sys
import datetime

# --- Path Configuration ---
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
SCRAPED_DB = os.path.join(BASE_DIR, 'assets', 'meds_scraped_new.jsonl')
MEDS_CSV = os.path.join(BASE_DIR, 'assets', 'meds.csv')
MEDS_BACKUP_CSV = os.path.join(BASE_DIR, 'assets', 'meds_backup.csv')
BACKUP_DIR = os.path.join(BASE_DIR, 'backups')

# --- Translation Dictionaries ---
MAIN_CATEGORIES = {
    'oncology': 'ÿπŸÑÿßÿ¨ ÿßŸÑÿ£Ÿàÿ±ÿßŸÖ',
    'diabetes_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ŸÖÿ±ÿ∂Ÿâ ÿßŸÑÿ≥ŸÉÿ±Ÿä',
    'skin_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ®ÿ¥ÿ±ÿ©',
    'eye_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿπŸäŸàŸÜ',
    'ear_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ£ÿ∞ŸÜ',
    'pain_management': 'ŸÖÿ≥ŸÉŸÜÿßÿ™ ÿßŸÑÿ£ŸÑŸÖ',
    'anesthetics': 'ÿßŸÑÿ™ÿÆÿØŸäÿ±',
    'anti_inflammatory': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑÿßŸÑÿ™Ÿáÿßÿ®',
    'antihistamine': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑŸáŸäÿ≥ÿ™ÿßŸÖŸäŸÜ',
    'anti_infective': 'ŸÖÿ∂ÿßÿØÿßÿ™ ÿßŸÑÿπÿØŸàŸâ',
    'vitamins': 'ÿßŸÑŸÅŸäÿ™ÿßŸÖŸäŸÜÿßÿ™',
    'supplements': 'ÿßŸÑŸÖŸÉŸÖŸÑÿßÿ™ ÿßŸÑÿ∫ÿ∞ÿßÿ¶Ÿäÿ©',
    'probiotics': 'ÿßŸÑÿ®ÿ±Ÿàÿ®ŸäŸàÿ™ŸäŸÉ',
    'respiratory': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿ™ŸÜŸÅÿ≥Ÿä',
    'digestive': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑŸáÿ∂ŸÖŸä',
    'cardiovascular': 'ÿßŸÑŸÇŸÑÿ® ŸàÿßŸÑÿ£ŸàÿπŸäÿ© ÿßŸÑÿØŸÖŸàŸäÿ©',
    'neurological': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿπÿµÿ®Ÿä',
    'urology': 'ÿßŸÑŸÖÿ≥ÿßŸÑŸÉ ÿßŸÑÿ®ŸàŸÑŸäÿ©',
    'soothing': 'ŸÖŸáÿØÿ¶ÿßÿ™',
    'cosmetics': 'ŸÖÿ≥ÿ™ÿ≠ÿ∂ÿ±ÿßÿ™ ÿßŸÑÿ™ÿ¨ŸÖŸäŸÑ',
    'personal_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿßŸÑÿ¥ÿÆÿµŸäÿ©',
    'medical_supplies': 'ŸÖÿ≥ÿ™ŸÑÿ≤ŸÖÿßÿ™ ÿ∑ÿ®Ÿäÿ©',
    'hormonal': 'ÿßŸÑŸáÿ±ŸÖŸàŸÜÿßÿ™',
    'hematology': 'ÿ£ŸÖÿ±ÿßÿ∂ ÿßŸÑÿØŸÖ',
    'musculoskeletal': 'ÿßŸÑÿ¨Ÿáÿßÿ≤ ÿßŸÑÿπÿ∂ŸÑŸä ÿßŸÑŸáŸäŸÉŸÑŸä',
    'immunology': 'ÿßŸÑŸÖŸÜÿßÿπÿ©',
    'reproductive_health': 'ÿßŸÑÿµÿ≠ÿ© ÿßŸÑÿ•ŸÜÿ¨ÿßÿ®Ÿäÿ©',
    'herbal_natural': 'ÿ£ÿπÿ¥ÿßÿ® ŸàŸÖŸàÿßÿØ ÿ∑ÿ®ŸäÿπŸäÿ©',
    'baby_care': 'ÿßŸÑÿπŸÜÿßŸäÿ© ÿ®ÿßŸÑÿ∑ŸÅŸÑ',
    'medical_devices': 'ÿ£ÿ¨Ÿáÿ≤ÿ© ÿ∑ÿ®Ÿäÿ©',
    'diagnostics': 'ÿßŸÑÿ™ÿ¥ÿÆŸäÿµ',
    'other': 'ÿ£ÿÆÿ±Ÿâ'
}

DOSAGE_FORM_TRANSLATIONS = {
    'tablets': 'ÿ£ŸÇÿ±ÿßÿµ', 'capsules': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™', 'syrup': 'ÿ¥ÿ±ÿßÿ®', 'suspension': 'ŸÖÿπŸÑŸÇ',
    'injection': 'ÿ≠ŸÇŸÜ', 'ampoules': 'ÿ£ŸÖÿ®ŸàŸÑÿßÿ™', 'ampoule': 'ÿ£ŸÖÿ®ŸàŸÑÿ©', 'vial': 'ŸÅŸäÿßŸÑ',
    'cream': 'ŸÉÿ±ŸäŸÖ', 'ointment': 'ŸÖÿ±ŸáŸÖ', 'gel': 'ÿ¨ŸÑ', 'drops': 'ŸÜŸÇÿ∑',
    'eye_drops': 'ŸÜŸÇÿ∑ ŸÑŸÑÿπŸäŸÜ', 'eye_ointment': 'ŸÖÿ±ŸáŸÖ ŸÑŸÑÿπŸäŸÜ', 'ear_drops': 'ŸÜŸÇÿ∑ ŸÑŸÑÿ£ÿ∞ŸÜ',
    'effervescent': 'ŸÅŸàÿßÿ±', 'nasal_spray': 'ÿ®ÿÆÿßÿÆ ŸÑŸÑÿ£ŸÜŸÅ', 'inhaler': 'ÿ¨Ÿáÿßÿ≤ ÿßÿ≥ÿ™ŸÜÿ¥ÿßŸÇ',
    'suppositories': 'ŸÑÿ®Ÿàÿ≥', 'suppository': 'ŸÑÿ®Ÿàÿ≥ÿ©', 'powder': 'ÿ®ŸàÿØÿ±ÿ©', 'sachets': 'ÿ£ŸÉŸäÿßÿ≥',
    'lozenges': 'ÿ£ŸÇÿ±ÿßÿµ ÿßÿ≥ÿ™ÿ≠ŸÑÿßÿ®', 'shampoo': 'ÿ¥ÿßŸÖÿ®Ÿà', 'lotion': 'ŸÑŸàÿ¥ŸÜ', 'solution': 'ŸÖÿ≠ŸÑŸàŸÑ',
    'spray': 'ÿ®ÿÆÿßÿÆ', 'patch': 'ŸÑÿµŸÇÿ©', 'oral_gel': 'ÿ¨ŸÑ ŸÅŸÖŸàŸä', 'oral_drops': 'ŸÜŸÇÿ∑ ÿ®ÿßŸÑŸÅŸÖ',
    'oral_suspension': 'ŸÖÿπŸÑŸÇ ŸÅŸÖŸàŸä', 'effervescent_tablets': 'ÿ£ŸÇÿ±ÿßÿµ ŸÅŸàÿßÿ±ÿ©',
    'chewable_tablets': 'ÿ£ŸÇÿ±ÿßÿµ ŸÑŸÑŸÖÿ∂ÿ∫', 'soft_gelatin_capsules': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™ ÿ¨ŸäŸÑÿßÿ™ŸäŸÜŸäÿ© ÿ±ÿÆŸàÿ©',
    'hard_gelatin_capsules': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™ ÿ¨ŸäŸÑÿßÿ™ŸäŸÜŸäÿ© ÿµŸÑÿ®ÿ©', 'hair_oil': 'ÿ≤Ÿäÿ™ ÿ¥ÿπÿ±',
    'vaginal_suppositories': 'ŸÑÿ®Ÿàÿ≥ ŸÖŸáÿ®ŸÑŸä', 'vaginal_cream': 'ŸÉÿ±ŸäŸÖ ŸÖŸáÿ®ŸÑŸä',
    'vaginal_gel': 'ÿ¨ŸÑ ŸÖŸáÿ®ŸÑŸä', 'vaginal_douche': 'ÿØÿ¥ ŸÖŸáÿ®ŸÑŸä', 'enema': 'ÿ≠ŸÇŸÜÿ© ÿ¥ÿ±ÿ¨Ÿäÿ©',
    'mouthwash': 'ÿ∫ÿ≥ŸàŸÑ ŸÅŸÖ', 'toothpaste': 'ŸÖÿπÿ¨ŸàŸÜ ÿ£ÿ≥ŸÜÿßŸÜ', 'soap': 'ÿµÿßÿ®ŸàŸÜ',
    'intravenous_infusion': 'ÿ™ÿ≥ÿ±Ÿäÿ® Ÿàÿ±ŸäÿØŸä', 'subcutaneous_injection': 'ÿ≠ŸÇŸÜ ÿ™ÿ≠ÿ™ ÿßŸÑÿ¨ŸÑÿØ',
    'intramuscular_injection': 'ÿ≠ŸÇŸÜ ÿπÿ∂ŸÑŸä', 'topical_solution': 'ŸÖÿ≠ŸÑŸàŸÑ ŸÖŸàÿ∂ÿπŸä',
    'topical_spray': 'ÿ®ÿÆÿßÿÆ ŸÖŸàÿ∂ÿπŸä', 'topical_gel': 'ÿ¨ŸÑ ŸÖŸàÿ∂ÿπŸä', 'topical_cream': 'ŸÉÿ±ŸäŸÖ ŸÖŸàÿ∂ÿπŸä',
    'transdermal_patch': 'ŸÑÿµŸÇÿ© ÿπÿ®ÿ± ÿßŸÑÿ¨ŸÑÿØ', 'film-coated_tablets': 'ÿ£ŸÇÿ±ÿßÿµ ŸÖÿ∫ŸÑŸÅÿ©',
    'extended-release_tablets': 'ÿ£ŸÇÿ±ÿßÿµ ŸÖŸÖÿ™ÿØÿ© ÿßŸÑŸÖŸÅÿπŸàŸÑ', 'delayed-release_capsules': 'ŸÉÿ®ÿ≥ŸàŸÑÿßÿ™ ŸÖÿ§ÿ¨ŸÑÿ© ÿßŸÑŸÖŸÅÿπŸàŸÑ',
    'rectal_suppositories': 'ŸÑÿ®Ÿàÿ≥ ÿ¥ÿ±ÿ¨Ÿä', 'vaginal_tablets': 'ÿ£ŸÇÿ±ÿßÿµ ŸÖŸáÿ®ŸÑŸäÿ©',
    'pre-filled_syringe': 'ÿ≠ŸÇŸÜÿ© ŸÖÿπÿ®ÿ£ÿ© ŸÖÿ≥ÿ®ŸÇŸãÿß', 'pen': 'ŸÇŸÑŸÖ', 'piece': 'ŸÇÿ∑ÿπÿ©',
    'unknown': 'ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ', 'tablet': 'ŸÇÿ±ÿµ', 'capsule': 'ŸÉÿ®ÿ≥ŸàŸÑÿ©'
}

USAGE_TRANSLATIONS = {
    'eff': 'ŸÅŸàÿßÿ±', 'oral': 'ÿπŸÜ ÿ∑ÿ±ŸäŸÇ ÿßŸÑŸÅŸÖ', 'oral.liquid': 'ÿ≥ÿßÿ¶ŸÑ ŸÅŸÖŸàŸä', 'oral.solid': 'ÿµŸÑÿ® ŸÅŸÖŸàŸä',
    'topical': 'ŸÖŸàÿ∂ÿπŸä', 'unknown': 'ÿ∫Ÿäÿ± ŸÖÿπÿ±ŸàŸÅ', 'injection': 'ÿ≠ŸÇŸÜ', 'inhalation': 'ÿßÿ≥ÿ™ŸÜÿ¥ÿßŸÇ',
    'rectal': 'ÿ¥ÿ±ÿ¨Ÿä', 'soap': 'ÿµÿßÿ®ŸàŸÜ', 'spray': 'ÿ®ÿÆÿßÿÆ', 'vaginal': 'ŸÖŸáÿ®ŸÑŸä',
    'ophthalmic': 'ŸÑŸÑÿπŸäŸÜ', 'otic': 'ŸÑŸÑÿ£ÿ∞ŸÜ', 'nasal': 'ŸÑŸÑÿ£ŸÜŸÅ', 'sublingual': 'ÿ™ÿ≠ÿ™ ÿßŸÑŸÑÿ≥ÿßŸÜ',
    'buccal': 'ÿ¥ÿØŸÇŸä', 'transdermal': 'ÿπÿ®ÿ± ÿßŸÑÿ¨ŸÑÿØ', 'intravenous': 'Ÿàÿ±ŸäÿØŸä',
    'intramuscular': 'ÿπÿ∂ŸÑŸä', 'subcutaneous': 'ÿ™ÿ≠ÿ™ ÿßŸÑÿ¨ŸÑÿØ'
}

def safe_str_lower(value):
    return str(value).lower() if value else ''

def main():
    print(f"üîÑ Updating meds.csv from {SCRAPED_DB}...")
    
    if not os.path.exists(SCRAPED_DB):
        print("‚ùå Scraped DB not found. Run scraper first.")
        sys.exit(1)
        
    # 1. Backup Existing CSVs (Safe Backup)
    if os.path.exists(MEDS_CSV):
        # Check if MEDS_CSV is valid/substantial before backing up
        # This prevents the scraper's "wipe" from destroying the backup source
        is_valid_csv = False
        try:
            if os.path.getsize(MEDS_CSV) > 100: # Arbitrary small threshold
                is_valid_csv = True
            else:
                # Double check line count
                with open(MEDS_CSV, 'r') as f:
                    if len(f.readlines()) > 5:
                         is_valid_csv = True
        except: pass

        if is_valid_csv:
            print("üíæ Creating Backups...")
            os.makedirs(BACKUP_DIR, exist_ok=True)
            timestamp = datetime.datetime.now().strftime('%Y%m%d_%H%M%S')
            
            # Backup 1: To backups/ folder with timestamp
            backup_path = os.path.join(BACKUP_DIR, f'meds_backup_{timestamp}.csv')
            shutil.copy(MEDS_CSV, backup_path)
            print(f"   -> {backup_path}")
            
            # Backup 2: To assets/meds_backup.csv (Overwrite previous backup)
            shutil.copy(MEDS_CSV, MEDS_BACKUP_CSV)
            print(f"   -> {MEDS_BACKUP_CSV}")
        else:
            print("‚ö†Ô∏è Skipping backup: meds.csv is too small/empty (preventing data loss).")

    # 2. Load Scraped Data
    scraped_map = {}
    print(f"üìÇ Loading scraped data...")
    with open(SCRAPED_DB, 'r', encoding='utf-8') as f:
        for line in f:
            if line.strip():
                try:
                    rec = json.loads(line)
                    mid = str(rec.get('id', ''))
                    if mid:
                        scraped_map[mid] = rec
                except json.JSONDecodeError as e:
                    print(f"‚ùå JSON Error in line: {e} | Content: {line[:50]}...")
                except Exception as e:
                    print(f"‚ùå Error parsing line: {e}")
    
    count = len(scraped_map)
    print(f"‚úÖ Loaded {count} scraped records.")
    
    if count == 0:
        print("‚ö†Ô∏è  Warning: Scraped data is empty! Aborting overwrite to prevent data loss.")
        sys.exit(1)

    # 3. Build New Records (Strict Overwrite)
    print("üî® Processing records (Wiping old data)...")
    records = []
    
    for mid, rec in scraped_map.items():
        # Handle date mapping robustly
        date_val = rec.get('last_update') or rec.get('last_price_update') or ''
        
        # Base Row
        row = {
            'id': mid,
            'trade_name': rec.get('trade_name', ''),
            'arabic_name': rec.get('arabic_name', ''),
            'price': rec.get('price', ''),
            'old_price': rec.get('old_price', ''),
            'active': rec.get('active', ''),
            'company': rec.get('company', ''),
            'category': rec.get('category', ''),
            'last_price_update': date_val,
            'visits': rec.get('visits', ''),
            'concentration': rec.get('concentration', ''),
            'pharmacology': rec.get('pharmacology', ''),
            'barcode': rec.get('barcode', ''),
            'unit': rec.get('units', ''),
            'dosage_form': rec.get('dosage_form', ''),
            'usage': rec.get('usage', ''),
        }
        
        # --- Translation & Enrichment ---
        
        # Dosage Form AR
        form_lower = safe_str_lower(row['dosage_form'])
        row['dosage_form_ar'] = DOSAGE_FORM_TRANSLATIONS.get(form_lower, '')
        if not row['dosage_form_ar']:
            # Fallback: Check if any key is substring
            for key, val in DOSAGE_FORM_TRANSLATIONS.items():
                if key in form_lower:
                    row['dosage_form_ar'] = val
                    break
        
        # Usage AR
        usage_lower = safe_str_lower(row['usage'])
        row['usage_ar'] = USAGE_TRANSLATIONS.get(usage_lower, '')
        
        # Category AR & Main Category
        # (Could use MAIN_CATEGORIES later if we map them)
        row['category_ar'] = '' # Placeholder
        row['main_category'] = 'Other' 
        row['main_category_ar'] = 'ÿ£ÿÆÿ±Ÿâ'
        
        records.append(row)

    # 4. Create DataFrame & Save
    df = pd.DataFrame(records)
    
    # Define Column Order (Schema)
    # Define Column Order (Schema) - Description REMOVED per user request
    desired_columns = [
        'id', 'trade_name', 'arabic_name', 'price', 'old_price', 'active', 
        'company', 'dosage_form', 'dosage_form_ar', 
        'usage', 'usage_ar', 'category', 'category_ar', 
        'main_category', 'main_category_ar', 'concentration', 
        'pharmacology', 'barcode', 'unit', 'visits', 'last_price_update'
    ]
    
    # Ensure all columns exist
    for col in desired_columns:
        if col not in df.columns:
            df[col] = ''
            
    # Remove duplicates columns if any (by name)
    df = df.loc[:, ~df.columns.duplicated()]
    
    # Reorder and Select (Strict)
    df = df[desired_columns]
    
    # Save (Overwrite)
    df.to_csv(MEDS_CSV, index=False, encoding='utf-8-sig') # Use utf-8-sig for Excel compatibility
    print(f"‚úÖ SUCCESS: Wiped old data and wrote {len(df)} records to {MEDS_CSV}")

if __name__ == "__main__":
    main()
