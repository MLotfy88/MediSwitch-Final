name: NCBI StatPearls Scraper

on:
  workflow_dispatch:
  schedule:
    - cron: '0 */6 * * *' # Run every 6 hours

jobs:
  scrape-ncbi:
    runs-on: ubuntu-latest
    timeout-minutes: 480 # 8 hours (increased from 5)
    permissions:
      contents: write

    steps:
      - name: Checkout repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install requests aiohttp beautifulsoup4

      - name: Reconstruct Database (for Target Gen)
        run: |
          echo "Reconstructing DB for ingredient list..."
          cat assets/database/parts/mediswitch.db.part-* > assets/database/mediswitch.db
          ls -lh assets/database/mediswitch.db

      - name: Generate Targets (Continue Discovery)
        run: |
          echo "Running target generator (resumes automatically)..."
          timeout 360m python3 scripts/statpearls_scraper/generate_targets.py || echo "Generator completed or timeout"

      - name: Run Async Scraper
        run: python3 scripts/statpearls_scraper/async_scraper.py
        env:
          PYTHONUNBUFFERED: 1

      - name: Commit Scraped Data
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          commit_message: "feat(data): update ncbi statpearls scraped data [skip ci]"
          file_pattern: 'scripts/statpearls_scraper/'
          skip_dirty_check: true
          skip_fetch: true
          skip_checkout: true
