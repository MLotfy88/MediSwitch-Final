name: High-Fidelity D1 Sync

on:
  workflow_dispatch:  # Manual trigger
  push:
    branches: [main]
    paths:
      - 'assets/meds.csv'
      - 'assets/data/**'
      - 'scripts/rebuild_d1_data.py'
      - 'export_mediswitch_to_sql.py'
      - 'd1_sql_chunks/**'

jobs:
  sync-d1:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout
        uses: actions/checkout@v4
      
      - name: Setup Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: '20'
      
      - name: Install Wrangler
        run: npm install -g wrangler
      
      - name: Resilient Deploy to Cloudflare D1
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
          DB_NAME: "mediswitsh-db"
        run: |
          echo "ðŸš€ Generating SQL Chunks from source assets..."
          mkdir -p d1_sql_chunks
          python3 scripts/rebuild_d1_data.py
          
          echo "ðŸš€ Starting Resilient D1 Data Sync (On-the-fly Generated)..."
          
          # Function to execute a pattern of files
          execute_pattern() {
            local pattern=$1
            local label=$2
            echo "ðŸ“¦ Deploying $label dataset ($pattern)..."
            FILES=$(find d1_sql_chunks/ -maxdepth 1 -name "$pattern" | sort)
            if [ -z "$FILES" ]; then
              echo "  âš ï¸ No files matching $pattern found."
              return
            fi
            
            for f in $FILES; do
              echo "  - Executing $f..."
              for i in {1..3}; do
                if npx wrangler d1 execute $DB_NAME --yes --remote --file="$f"; then
                  echo "    âœ… Success: $f"
                  break
                else
                  if [ $i -eq 3 ]; then
                    echo "    âŒ ERROR: Failed after 3 attempts: $f"
                    exit 1
                  fi
                  echo "    âš ï¸ Attempt $i failed. Retrying in 5s..."
                  sleep 5
                fi
              done
              # Small pause to prevent rate limiting
              sleep 1
            done
          }
          
          # 1. Apply Schema first (from main schema file or d1_migration_sql)
          echo "ðŸ“„ Applying Schema..."
          if [ -f "d1_migration_sql/01_schema.sql" ]; then
            npx wrangler d1 execute $DB_NAME --yes --remote --file=d1_migration_sql/01_schema.sql
          elif [ -f "cloudflare-worker/schema.sql" ]; then
            npx wrangler d1 execute $DB_NAME --yes --remote --file=cloudflare-worker/schema.sql
          else
            echo "âš ï¸ No schema file found, skipping..."
          fi
          
          # 2. Deploy all datasets in order (from d1_sql_chunks/)
          execute_pattern "d1_import_part_*.sql" "Drugs"
          execute_pattern "d1_rules_part_*.sql" "Drug Interactions"
          execute_pattern "d1_ingredients_part_*.sql" "Med Ingredients"
          execute_pattern "d1_food_part_*.sql" "Food Interactions"
          execute_pattern "d1_disease_part_*.sql" "Disease Interactions"
          execute_pattern "d1_dosages_part_*.sql" "Dosage Guidelines"
          
          echo "âœ… High-Fidelity Sync Complete!"
      
      - name: Final Database Verification
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "ðŸ” Verifying D1 database counts..."
          npx wrangler d1 execute mediswitsh-db --remote --yes --command="SELECT (SELECT COUNT(*) FROM drugs) as drugs, (SELECT COUNT(*) FROM drug_interactions) as interactions;" --config=cloudflare-worker/wrangler.toml
      
      
      - name: Detailed D1 Audit Report
        if: always()
        env:
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "ðŸ“Š Generating detailed D1 database report..."
          python3 scripts/audit_d1_database.py > d1_audit_report.txt
          
          echo "## ðŸ“Š ØªÙ‚Ø±ÙŠØ± Ù…Ø²Ø§Ù…Ù†Ø© D1 Ø§Ù„Ù…ÙØµÙ„" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          cat d1_audit_report.txt >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "**Database:** mediswitsh-db" >> $GITHUB_STEP_SUMMARY
          echo "**Worker API:** https://mediswitch-api.m-m-lotfy-88.workers.dev" >> $GITHUB_STEP_SUMMARY
          echo "**Admin Dashboard:** https://mediswitch-admin-dashboard.pages.dev" >> $GITHUB_STEP_SUMMARY
