name: ğŸš€ Advanced Dosage Data Enrichment

# Workflow Ø®Ø§Ø±Ù‚ Ù„Ø¥Ø«Ø±Ø§Ø¡ ÙˆØ§Ø³ØªÙƒÙ…Ø§Ù„ Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø¬Ø±Ø¹Ø§Øª Ù…Ù† Ù…ØµØ§Ø¯Ø± Ù…ØªØ¹Ø¯Ø¯Ø©
# ÙŠØ¬Ù…Ø¹ Ø¨ÙŠÙ† DailyMed, WHO ATC/DDD, Ùˆ OpenFDA Ù…Ø¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø°ÙƒÙŠØ© ÙˆØªÙ†Ø¸ÙŠÙ ØªÙ„Ù‚Ø§Ø¦ÙŠ

on:
  schedule:
    # ÙŠØ¹Ù…Ù„ ÙŠÙˆÙ… Ø§Ù„Ø£Ø­Ø¯ ÙÙŠ Ù…Ù†ØªØµÙ Ø§Ù„Ù„ÙŠÙ„ UTC (Ø§Ù„ØªØ­Ø¯ÙŠØ« Ø§Ù„Ø£Ø³Ø¨ÙˆØ¹ÙŠ)
    - cron: '0 0 * * 0'
  workflow_dispatch:  # Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„ÙŠØ¯ÙˆÙŠ
    inputs:
      skip_download:
        description: 'ØªØ®Ø·ÙŠ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ø®Ø§Ø±Ø¬ÙŠØ© (Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ù…Ù„ÙØ§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)'
        required: false
        default: 'false'
      full_rebuild:
        description: 'Ø¥Ø¹Ø§Ø¯Ø© Ø¨Ù†Ø§Ø¡ ÙƒØ§Ù…Ù„Ø© (Ø­Ø°Ù Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª Ø§Ù„Ù…ÙˆØ¬ÙˆØ¯Ø©)'
        required: false
        default: 'false'
      sources:
        description: 'Ø§Ù„Ù…ØµØ§Ø¯Ø± Ø§Ù„Ù…Ø·Ù„ÙˆØ¨Ø© (dailymed,who,openfda Ø£Ùˆ all)'
        required: false
        default: 'all'

env:
  PYTHON_VERSION: '3.11'
  DOSAGE_JSON: 'assets/data/dosage_guidelines.json.gz'
  WHO_CSV: 'assets/external_research_data/WHO_ATC_DDD_2024.csv'
  DAILYMED_DIR: 'External_source/dailymed/downloaded'
  OPENFDA_DIR: 'External_source/drug_interaction/drug-label/downloaded'
  DATALAKE_FILE: 'production_data/production_dosages.jsonl'

jobs:
  enrich-dosage-data:
    runs-on: ubuntu-latest
    timeout-minutes: 240  # 4 hours Ù„Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ù‚Ø¯Ø©
    
    steps:
      # ============================================
      # ğŸ“¦ SETUP & PREPARATION
      # ============================================
      - name: ğŸ“¥ Checkout Repository
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Ù„Ù„ÙˆØµÙˆÙ„ Ø§Ù„ÙƒØ§Ù…Ù„ Ù„Ù„ØªØ§Ø±ÙŠØ®
          
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ env.PYTHON_VERSION }}
          cache: 'pip'
          
      - name: ğŸ“š Install Dependencies
        run: |
          pip install --upgrade pip
          pip install requests pandas beautifulsoup4 aiohttp aiofiles
          pip install openpyxl csvkit sqlite-utils
          
      - name: ğŸ” Environment Check
        run: |
          echo "ğŸ”¹ Python: $(python3 --version)"
          echo "ğŸ”¹ Starting at: $(date '+%Y-%m-%d %H:%M:%S UTC')"
          echo "ğŸ”¹ Workflow triggered by: ${{ github.event_name }}"
          echo "ğŸ”¹ Skip Download: ${{ github.event.inputs.skip_download }}"
          echo "ğŸ”¹ Full Rebuild: ${{ github.event.inputs.full_rebuild }}"
          echo "ğŸ”¹ Sources: ${{ github.event.inputs.sources }}"
          
      # ============================================
      # ğŸ“Š BACKUP CURRENT DATA
      # ============================================
      - name: ğŸ’¾ Backup Current Dosage Data
        run: |
          BACKUP_DIR="backups/$(date +'%Y%m%d')"
          mkdir -p "$BACKUP_DIR"
          
          if [ -f "$DOSAGE_JSON" ]; then
            cp "$DOSAGE_JSON" "$BACKUP_DIR/dosage_guidelines_backup.json.gz"
            RECORD_COUNT=$(python3 -c "import json, gzip; print(len(json.load(gzip.open('$DOSAGE_JSON', 'rt', encoding='utf-8'))))")
            echo "âœ… Backed up $RECORD_COUNT records to $BACKUP_DIR"
            echo "baseline_count=$RECORD_COUNT" >> $GITHUB_ENV
          else
            echo "âš ï¸ No existing dosage file found, starting fresh"
            echo "baseline_count=0" >> $GITHUB_ENV
          fi
          
      # ============================================
      # ğŸŒ STEP 1: WHO ATC/DDD DATA ENRICHMENT
      # ============================================
      - name: ğŸŒ Enrich from WHO ATC/DDD Database
        if: github.event.inputs.sources == 'all' || github.event.inputs.sources == 'who' || github.event.inputs.sources == ''
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸŒ WHO ATC/DDD ENRICHMENT"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          if [ ! -f "$WHO_CSV" ]; then
            echo "âŒ WHO CSV file not found: $WHO_CSV"
            exit 1
          fi
          
          python3 enrich_dosages_who.py
          
          # Count additions
          AFTER_WHO=$(python3 -c "import json, gzip; print(len(json.load(gzip.open('$DOSAGE_JSON', 'rt', encoding='utf-8'))))")
          WHO_ADDED=$((AFTER_WHO - baseline_count))
          echo "who_added=$WHO_ADDED" >> $GITHUB_ENV
          echo "âœ… WHO enrichment complete: +$WHO_ADDED records"
          
      # ============================================
      # ğŸ“¥ STEP 2: DOWNLOAD EXTERNAL DATA SOURCES
      # ============================================
      - name: ğŸ“¥ Download & Process DailyMed (Streamlined)
        if: (github.event.inputs.skip_download != 'true') && (github.event.inputs.sources == 'all' || github.event.inputs.sources == 'dailymed' || github.event.inputs.sources == '')
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“¥ STREAMING DAILYMED (Download -> Extract -> Delete)"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          # Use new streamlined script to save disk space
          python3 scripts/stream_dailymed.py
          
          if [ -f "production_data/dailymed_full_database.jsonl.gz" ]; then
            SIZE=$(du -h production_data/dailymed_full_database.jsonl.gz | cut -f1)
            echo "âœ… Data Lake created: $SIZE"
          fi

      - name: ğŸ“¥ Download OpenFDA Drug Labels
        if: (github.event.inputs.skip_download != 'true') && (github.event.inputs.sources == 'all' || github.event.inputs.sources == 'openfda' || github.event.inputs.sources == '')
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“¥ DOWNLOADING OPENFDA LABELS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          mkdir -p "$OPENFDA_DIR"
          python3 scripts/dosage/download_openfda_labels.py
          
      - name: ğŸ—ï¸ Process Data Lake into Production Dosages
        if: github.event.inputs.sources == 'all' || github.event.inputs.sources == 'dailymed' || github.event.inputs.sources == ''
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ—ï¸ PROCESSING DATA LAKE"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/process_datalake.py
          
          if [ -f "$DATALAKE_FILE" ]; then
            LAKE_COUNT=$(wc -l < "$DATALAKE_FILE")
            echo "lake_records=$LAKE_COUNT" >> $GITHUB_ENV
            echo "âœ… Processed $LAKE_COUNT production records"
          fi
          
      # ============================================
      # ğŸ©¹ STEP 4: HEAL TRUNCATED RECORDS
      # ============================================
      - name: ğŸ©¹ Heal Truncated Dosage Instructions
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ©¹ HEALING TRUNCATED RECORDS"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/heal_dosages.py

      # ============================================
      # ğŸ§¼ STEP 4.5: PURIFY & ENRICH DATA
      # ============================================
      - name: ğŸ§¼ Purify Text & Extract Fields
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ§¼ PURIFYING DOSAGE DATA"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/purify_dosages.py
          
      # ============================================
      # ğŸ§ª STEP 5: EXTRACT FROM OPENFDA
      # ============================================
      - name: ğŸ§ª Extract OpenFDA Dosages (Supplementary)
        if: github.event.inputs.sources == 'all' || github.event.inputs.sources == 'openfda' || github.event.inputs.sources == ''
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ§ª EXTRACTING OPENFDA DOSAGES"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/interactions/extract_dosages_optimized.py
          
      # ============================================
      # ğŸ§¹ STEP 6: DATA QUALITY & DEDUPLICATION
      # ============================================
      - name: ğŸ§¹ Deduplicate & Quality Check
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ§¹ DEDUPLICATION & QUALITY ASSURANCE"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/deduplicate_dosages.py
          
          # Load quality metrics to env
          source quality_report.txt
          echo "final_count=$final_count" >> $GITHUB_ENV
          echo "who_count=$who_count" >> $GITHUB_ENV
          echo "dailymed_count=$dailymed_count" >> $GITHUB_ENV
          echo "truncated_remaining=$truncated_remaining" >> $GITHUB_ENV
          
      # ============================================
      # ğŸ“Š STEP 6.5: EXPORT CSV FILES
      # ============================================
      - name: ğŸ“Š Export CSV for Inspection
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "ğŸ“Š EXPORTING CSV FILES"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/export_dosages_csv.py
          
          # Display sample stats
          if [ -f "exports/dosage_guidelines_full.csv" ]; then
            FULL_SIZE=$(wc -l < exports/dosage_guidelines_full.csv)
            echo "âœ… Full CSV: $FULL_SIZE rows"
            echo "full_csv_rows=$FULL_SIZE" >> $GITHUB_ENV
          fi
          
          if [ -f "exports/dosage_guidelines_sample.csv" ]; then
            SAMPLE_SIZE=$(wc -l < exports/dosage_guidelines_sample.csv)
            echo "âœ… Sample CSV: $SAMPLE_SIZE rows"
            echo "sample_csv_rows=$SAMPLE_SIZE" >> $GITHUB_ENV
          fi
          
      # ============================================
      # â˜ï¸ STEP 7: SYNC TO CLOUDFLARE D1
      # ============================================
      - name: â˜ï¸ Upload to Cloudflare D1
        if: github.event_name != 'workflow_dispatch' || github.event.inputs.full_rebuild == 'true'
        env:
          CLOUDFLARE_ACCOUNT_ID: ${{ secrets.CLOUDFLARE_ACCOUNT_ID }}
          D1_DATABASE_ID: ${{ secrets.D1_DATABASE_ID }}
          CLOUDFLARE_API_TOKEN: ${{ secrets.CLOUDFLARE_API_TOKEN }}
        run: |
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          echo "â˜ï¸ SYNCING TO CLOUDFLARE D1"
          echo "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”"
          
          python3 scripts/upload_dosage_d1.py \
            --json-file "$DOSAGE_JSON" \
            --database-id "$D1_DATABASE_ID" \
            --account-id "$CLOUDFLARE_ACCOUNT_ID" \
            --api-token "$CLOUDFLARE_API_TOKEN"
          
      # ============================================
      # ğŸ“ STEP 8: COMMIT CHANGES
      # ============================================
      - name: ğŸ“ Commit Enriched Data
        run: |
          git config --global user.name 'Dosage Enrichment Bot'
          git config --global user.email 'bot@mediswitch.local'
          
          # Create detailed commit message
          echo "data: dosage enrichment $(date +'%Y-%m-%d')" > commit_message.txt
          echo "" >> commit_message.txt
          echo "ğŸš€ Advanced Dosage Data Enrichment Complete" >> commit_message.txt
          echo "" >> commit_message.txt
          echo "ğŸ“Š Statistics:" >> commit_message.txt
          echo "- Baseline: ${{ env.baseline_count }} records" >> commit_message.txt
          echo "- Final: ${{ env.final_count }} records" >> commit_message.txt
          echo "- Net Growth: $((${{ env.final_count }} - ${{ env.baseline_count }}))" >> commit_message.txt
          echo "" >> commit_message.txt
          echo "ğŸ“ˆ Sources:" >> commit_message.txt
          echo "- WHO ATC/DDD: ${{ env.who_count }} records" >> commit_message.txt
          echo "- DailyMed: ${{ env.dailymed_count }} records" >> commit_message.txt
          echo "- Still Truncated: ${{ env.truncated_remaining }} records" >> commit_message.txt
          echo "" >> commit_message.txt
          echo "ğŸ“Š Exports:" >> commit_message.txt
          echo "- Full CSV: ${{ env.full_csv_rows }} rows" >> commit_message.txt
          echo "- Sample CSV: ${{ env.sample_csv_rows }} rows" >> commit_message.txt
          echo "" >> commit_message.txt
          echo "ğŸ”„ Workflow: ${{ github.workflow }}" >> commit_message.txt
          echo "â° Completed: $(date '+%Y-%m-%d %H:%M:%S UTC')" >> commit_message.txt

          # Force add compressed production map only (exclude raw 156MB file)
          git add -f "$DOSAGE_JSON" backups/ exports/ production_data/production_dosages.jsonl.gz
          git commit -F commit_message.txt || echo "No changes to commit"
          
          # Handle concurrent updates (stash just in case, then pull-rebase)
          git stash
          git pull --rebase origin main
          git stash pop || echo "No stash to pop"
          git push origin main
          
      # ============================================
      # ğŸ“Š STEP 9: CREATE SUMMARY REPORT
      # ============================================
      - name: ğŸ“Š Generage Clinical Quality Report
        run: python3 scripts/analyze_quality.py

      - name: ğŸ“Š Generate Workflow Summary
        if: always()
        run: |
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          # ğŸš€ Dosage Data Enrichment Complete
          
          EOF
          
          # Append Quality Report
          if [ -f "quality_report.md" ]; then
            cat quality_report.md >> $GITHUB_STEP_SUMMARY
          fi
          
          cat >> $GITHUB_STEP_SUMMARY << 'EOF'
          
          ## ğŸ“Š Final Statistics
          
          | Metric | Value |
          |--------|-------|
          | Baseline Records | ${{ env.baseline_count }} |
          | Final Records | ${{ env.final_count }} |
          | **Net Growth** | **$((${{ env.final_count }} - ${{ env.baseline_count }}))** |
          
          ## ğŸ“ˆ Source Breakdown
          
          | Source | Count |
          |--------|-------|
          | WHO ATC/DDD 2024 | ${{ env.who_count }} |
          | DailyMed | ${{ env.dailymed_count }} |
          | Remaining Truncated | ${{ env.truncated_remaining }} |
          
          ## ğŸ“Š CSV Exports
          
          | File | Rows | Purpose |
          |------|------|---------|
          | `exports/dosage_guidelines_full.csv` | ${{ env.full_csv_rows }} | Complete dataset |
          | `exports/dosage_guidelines_sample.csv` | ${{ env.sample_csv_rows }} | Sample for inspection |
          
          ## âœ… Quality Assurance
          
          - âœ… Deduplication applied
          - âœ… Healing script executed
          - âœ… WHO data integrated
          - âœ… Data synced to D1
          - âœ… CSV exports generated
          
          **Download CSV files from the Actions artifacts for manual inspection.**
          
          ---
          
          **Workflow:** ${{ github.workflow }}  
          **Triggered by:** ${{ github.event_name }}  
          **Completed:** $(date '+%Y-%m-%d %H:%M:%S UTC')
          EOF
